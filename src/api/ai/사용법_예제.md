# Cloudflare Workers AI 고급 사용법 가이드

이 문서는 향상된 DestinyTellerApi의 고급 기능들을 활용하는 방법을 설명합니다.

## 🚀 주요 개선사항

### 1. AI Gateway 통합
- 요청/응답 로깅 및 모니터링
- 자동 캐싱으로 성능 향상
- 재시도 로직과 폴백 모델 설정
- 사용량 분석 및 비용 최적화

### 2. 고급 파라미터 지원
- 더 정밀한 텍스트 생성 제어
- 재현 가능한 결과를 위한 시드 설정
- 스트리밍 응답 지원

### 3. 자동 폴백 시스템
- 주 모델 실패 시 자동으로 대체 모델 사용
- 사주 분석에 최적화된 모델 선택 로직

### 4. 동적 모델 검색
- 사용 가능한 모델 실시간 조회
- 사주 분석 적합성 점수 기반 추천

## 📝 사용 예제

### 기본 사용법 (기존과 동일)

```javascript
const response = await fetch('/api/detailed-fortune-telling', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    systemPrompt: "당신은 전문 사주명리학자입니다.",
    userPrompt: "1990년 3월 15일 오전 10시 서울 출생자의 사주를 분석해주세요.",
    max_tokens: 1500,
    temperature: 0.3
  })
});
```

### AI Gateway 사용 (권장)

```javascript
const response = await fetch('/api/detailed-fortune-telling', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    systemPrompt: "당신은 전문 사주명리학자입니다.",
    userPrompt: "1990년 3월 15일 오전 10시 서울 출생자의 사주를 분석해주세요.",
    max_tokens: 2000,
    temperature: 0.4,
    
    // 🆕 AI Gateway 설정
    useGateway: true,
    gatewayId: "saju-analysis-gateway", // Cloudflare 대시보드에서 생성한 Gateway ID
    
    // 🆕 고급 옵션들
    top_p: 0.9,              // 더 창의적인 응답
    frequency_penalty: -0.1,  // 반복 줄이기
    presence_penalty: 0.1,    // 새로운 주제 장려
    seed: 12345,             // 재현 가능한 결과
    enableFallback: true     // 폴백 모델 사용
  })
});

const result = await response.json();

// 🔍 응답에는 추가 메타데이터 포함
console.log('사용된 모델:', result.metadata.model_used);
console.log('Gateway 사용:', result.metadata.gateway_enabled);
console.log('폴백 사용:', result.metadata.fallback_used);
```

### 스트리밍 응답 사용

```javascript
const response = await fetch('/api/detailed-fortune-telling', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    systemPrompt: "당신은 전문 사주명리학자입니다.",
    userPrompt: "사주 분석을 단계별로 자세히 설명해주세요.",
    
    // 🆕 스트리밍 설정
    stream: true,
    max_tokens: 3000,
    temperature: 0.5
  })
});

// 스트리밍 데이터 처리
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = new TextDecoder().decode(value);
  // 실시간으로 응답 표시
  console.log('스트림 데이터:', chunk);
}
```

### 특정 모델 선택

```javascript
const response = await fetch('/api/detailed-fortune-telling', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    systemPrompt: "당신은 전문 사주명리학자입니다.",
    userPrompt: "복잡한 사주 분석을 해주세요.",
    
    // 🆕 특정 모델 선택
    model: "@cf/qwen/qwen2.5-coder-32b-instruct", // 논리적 사고에 강한 모델
    max_tokens: 2500,
    temperature: 0.2, // 더 일관된 분석
    
    // 정밀한 제어
    top_p: 0.8,
    frequency_penalty: 0.0,
    presence_penalty: 0.2
  })
});
```

### 사용 가능한 모델 조회

```javascript
// 모든 모델 조회
const modelsResponse = await fetch('/api/ai-models');
const modelsData = await modelsResponse.json();

console.log('총 모델 수:', modelsData.total_count);
console.log('사주 분석 추천 모델:', modelsData.recommended_models);

// 특정 제공업체 모델만 조회
const metaModelsResponse = await fetch('/api/ai-models?provider=meta');
const metaModelsData = await metaModelsResponse.json();

// 텍스트 생성 모델만 조회
const textModelsResponse = await fetch('/api/ai-models?category=text-generation');
const textModelsData = await textModelsResponse.json();
```

### 디버깅을 위한 원시 응답

```javascript
const response = await fetch('/api/detailed-fortune-telling', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    systemPrompt: "당신은 전문 사주명리학자입니다.",
    userPrompt: "사주 분석을 해주세요.",
    
    // 🆕 원시 응답 반환 (디버깅용)
    returnRawResponse: true,
    max_tokens: 1000
  })
});

// 원시 Response 객체에 접근 가능
const rawData = await response.json();
console.log('응답 헤더:', rawData.headers);
console.log('상태 코드:', rawData.status);
```

## 🎯 모델별 특성 및 권장 사용법

### 1. @cf/deepseek-ai/deepseek-r1-distill-qwen-32b (기본)
- **특징**: 추론과 사고 과정에 특화
- **사주 분석 적합성**: ⭐⭐⭐⭐⭐
- **권장 설정**: temperature: 0.3-0.5, max_tokens: 1500-2500

### 2. @cf/qwen/qwen2.5-coder-32b-instruct
- **특징**: 논리적, 구조적 사고에 강함
- **사주 분석 적합성**: ⭐⭐⭐⭐⭐
- **권장 설정**: temperature: 0.2-0.4, top_p: 0.8

### 3. @cf/meta/llama-3.1-8b-instruct
- **특징**: 대화형 상호작용에 최적화
- **사주 분석 적합성**: ⭐⭐⭐⭐
- **권장 설정**: temperature: 0.4-0.6, presence_penalty: 0.1

### 4. @cf/google/gemma-7b-it
- **특징**: 효율적이고 빠른 추론
- **사주 분석 적합성**: ⭐⭐⭐
- **권장 설정**: 빠른 응답이 필요한 경우 사용

## 💡 최적화 팁

### 비용 최적화
```javascript
{
  // 짧은 분석용 - 비용 효율적
  max_tokens: 800,
  temperature: 0.3,
  model: "@cf/google/gemma-7b-it"
}

{
  // 상세한 분석용 - 품질 우선
  max_tokens: 2500,
  temperature: 0.4,
  model: "@cf/qwen/qwen2.5-coder-32b-instruct",
  useGateway: true // 캐싱으로 반복 요청 비용 절약
}
```

### 성능 최적화
```javascript
{
  // Gateway 캐싱 활용
  useGateway: true,
  gatewayId: "saju-cache-gateway",
  
  // 재현 가능한 결과 (캐싱 효율성 향상)
  seed: Math.floor(Date.now() / 1000), // 시간 기반 시드
  
  // 폴백 시스템 활성화
  enableFallback: true
}
```

### 품질 최적화
```javascript
{
  // 일관성 있는 분석
  temperature: 0.2,
  top_p: 0.8,
  frequency_penalty: 0.1,
  
  // 논리적 사고 모델 사용
  model: "@cf/qwen/qwen2.5-coder-32b-instruct",
  
  // 충분한 토큰 할당
  max_tokens: 2000
}
```

## 🔍 응답 헤더 정보

응답 헤더를 통해 추가 정보를 확인할 수 있습니다:

```javascript
const response = await fetch('/api/detailed-fortune-telling', { /* ... */ });

console.log('사용된 모델:', response.headers.get('X-AI-Model'));
console.log('Gateway 사용:', response.headers.get('X-Gateway-Enabled'));
console.log('폴백 사용:', response.headers.get('X-Fallback-Used'));
```

## ⚠️ 주의사항

1. **Gateway ID**: Cloudflare 대시보드에서 미리 설정한 Gateway ID를 사용해야 합니다.
2. **모델 가용성**: 일부 모델은 지역이나 플랜에 따라 사용할 수 없을 수 있습니다.
3. **토큰 제한**: 모델별로 최대 토큰 수가 다르므로 확인 후 사용하세요.
4. **비용 모니터링**: 고급 기능 사용 시 비용이 증가할 수 있으니 모니터링하세요.

## 📊 성능 모니터링

Gateway를 사용하면 Cloudflare 대시보드에서 다음 정보를 모니터링할 수 있습니다:

- 요청 횟수 및 성공률
- 평균 응답 시간
- 토큰 사용량 통계
- 모델별 성능 비교
- 비용 분석

이러한 고급 기능들을 활용하여 더 안정적이고 효율적인 사주 분석 서비스를 구축하세요! 